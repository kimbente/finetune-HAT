{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import torch\n",
    "import plotly.express as px\n",
    "from torchvision.io import write_png\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch cuda check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "# Cuda 12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3955884032, 25385107456)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.mem_get_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_xr = xr.load_dataset(\"~/data/nsidc/BedMachineAntarctica-v3.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y range in km 2099.5\n",
      "X range in km 1049.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2450000.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_max = 1800000 - 500 # 1900 km, -500 for midpoints\n",
    "train_y_min = -300000 # - 300 km\n",
    "\n",
    "train_x_max = 850000 - 500 # 900 km\n",
    "train_x_min = -200000 # - 200 km\n",
    "\n",
    "y_range = train_y_max - train_y_min\n",
    "x_range = train_x_max - train_x_min\n",
    "\n",
    "print(\"Y range in km\", y_range/1000)\n",
    "print(\"X range in km\", x_range/1000)\n",
    "\n",
    "# 2450 training images\n",
    "(train_x_max - train_x_min + 500) * (train_y_max - train_y_min + 500) / 900000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: converts from [0, 755] to {r, g, b} however some are not valid to convert back\n",
    "\n",
    "def cont_755_to_rbb(input):\n",
    "    # input: torch.Size([2450, 1, 60, 60])\n",
    "    # 0 - 255:\n",
    "    red = torch.where(condition = input < (255), input = input.int(), other = 255)\n",
    "    # 255 - 510:\n",
    "    green = torch.where(condition = (input > (255)), input = input.int() - 255, other = 0) # subtract 255\n",
    "    green = torch.where(condition = green < 255, input = green.int(), other = 255)\n",
    "    # 510 - 765:\n",
    "    blue = torch.where(condition = input > (255*2), input = (input - (255*2)).int(), other = 0)\n",
    "\n",
    "    rgb = torch.cat([red, green, blue], dim = 1)\n",
    "    \n",
    "    return(rgb.type(torch.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (x: 2100, y: 4200)\n",
      "Coordinates:\n",
      "  * x          (x) int32 -200000 -199500 -199000 ... 848500 849000 849500\n",
      "  * y          (y) int32 1799500 1799000 1798500 ... -299000 -299500 -300000\n",
      "Data variables:\n",
      "    mapping    |S1 b''\n",
      "    mask       (y, x) int8 2 2 2 2 2 2 2 2 2 2 2 2 2 ... 2 2 2 2 2 2 2 2 2 2 2 2\n",
      "    firn       (y, x) float32 18.97 18.98 19.0 19.01 ... 29.95 29.94 29.94 29.93\n",
      "    surface    (y, x) float32 1.945e+03 1.945e+03 ... 3.284e+03 3.283e+03\n",
      "    thickness  (y, x) float32 1.75e+03 1.755e+03 ... 2.586e+03 2.578e+03\n",
      "    bed        (y, x) float32 194.9 190.7 188.6 188.9 ... 704.5 697.6 705.3\n",
      "    errbed     (y, x) float32 34.0 32.0 30.0 30.0 30.0 ... 35.0 35.0 35.0 35.0\n",
      "    source     (y, x) int8 5 5 5 5 5 5 5 5 5 5 5 5 5 ... 5 5 5 5 5 5 5 5 5 5 5 5\n",
      "    dataid     (y, x) int8 0 2 0 0 0 0 2 2 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "    geoid      (y, x) int16 12 12 12 12 12 12 12 ... -23 -23 -23 -23 -23 -23 -23\n",
      "Attributes: (12/17)\n",
      "    Conventions:                 CF-1.7\n",
      "    Title:                       BedMachine Antarctica\n",
      "    Author:                      Mathieu Morlighem\n",
      "    version:                     03-Jun-2022 (v3.4)\n",
      "    nx:                          13333.0\n",
      "    ny:                          13333.0\n",
      "    ...                          ...\n",
      "    ymax:                        3333000\n",
      "    spacing:                     500\n",
      "    no_data:                     -9999.0\n",
      "    license:                     No restrictions on access or use\n",
      "    Data_citation:               Morlighem M. et al., (2019), Deep glacial tr...\n",
      "    Notes:                       Data processed at the Department of Earth Sy...\n"
     ]
    }
   ],
   "source": [
    "def export_train_images(bm_xr, d_y_min, d_y_max, d_x_min, d_x_max):\n",
    "\n",
    "    train_bm_xr = bm_xr.sel(x = slice(d_x_min, d_x_max), \n",
    "                            y = slice(d_y_max, d_y_min))\n",
    "    # Print to check dims\n",
    "    print(train_bm_xr)\n",
    "\n",
    "    train_tensor = torch.tensor(train_bm_xr.bed.values).unsqueeze(0)\n",
    "\n",
    "    IMAGE_DIM = 60\n",
    "    N_ROW_IMAGES = int(train_bm_xr.bed.values.shape[0]/IMAGE_DIM)\n",
    "    N_COLUMN_IMAGES = int(train_bm_xr.bed.values.shape[1]/IMAGE_DIM)\n",
    "\n",
    "    image_tensor = torch.empty(size = (0, 1, IMAGE_DIM, IMAGE_DIM))\n",
    "\n",
    "    for row in range(0, N_ROW_IMAGES):\n",
    "        row_min = row * IMAGE_DIM\n",
    "        row_max = row_min + IMAGE_DIM\n",
    "\n",
    "        for column in range(0, N_COLUMN_IMAGES):\n",
    "            column_min = column * IMAGE_DIM\n",
    "            column_max = column_min + IMAGE_DIM\n",
    "\n",
    "            image_tensor = torch.cat((image_tensor, train_tensor[:, row_min : row_max, column_min : column_max].unsqueeze(0)), dim = 0)\n",
    "\n",
    "    min_values, _ = torch.min(image_tensor.reshape(image_tensor.shape[0], -1), dim = -1)\n",
    "    max_values, _ = torch.max(image_tensor.reshape(image_tensor.shape[0], -1), dim = -1)\n",
    "    range_values = max_values - min_values\n",
    "\n",
    "    norm = torch.subtract(input = image_tensor.reshape(image_tensor.shape[0], -1), other = min_values.unsqueeze(1))\n",
    "    norm = torch.div(input = norm, other = range_values.unsqueeze(1))\n",
    "    norm = norm.reshape(image_tensor.shape)\n",
    "    cont_755 = norm * (3*255)\n",
    "\n",
    "    # Low qual\n",
    "    pool = nn.AvgPool2d(4, stride = 4)\n",
    "    cont_755_lq = pool(cont_755)\n",
    "    \n",
    "    rgb = cont_755_to_rbb(cont_755)\n",
    "    rgb_lq = cont_755_to_rbb(cont_755_lq)\n",
    "\n",
    "    n_images = rgb.shape[0]\n",
    "\n",
    "    for i in range(n_images):\n",
    "        # Create filename: string with contant length\n",
    "        number = str(i)\n",
    "        while(len(number) < 4):\n",
    "            number = '0' + number\n",
    "\n",
    "        name_hr = \"datasets/ANT_train/ANT_train_HR_sub/\" + number + \".png\"\n",
    "        #name_lr = \"datasets/ANT_train/ANT_train_LR_sub/X4_sub/\" + number + \"x4\" + \".png\"\n",
    "        name_lr = \"datasets/ANT_train/ANT_train_LR_sub/X4_sub/\" + number + \".png\"\n",
    "\n",
    "        # following https://data.vision.ee.ethz.ch/cvl/DIV2K/\n",
    "        write_png(rgb[i, :, :, :].type(torch.uint8), filename = name_hr)\n",
    "        write_png(rgb_lq[i, :, :, :].type(torch.uint8), filename = name_lr)\n",
    "    \n",
    "export_train_images(bm_xr, train_y_min, train_y_max, train_x_min, train_x_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y range in km 2099.5\n",
      "X range in km 59.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140000.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_max = 1800000 - 500# 1900 km\n",
    "val_y_min = -300000 # - 300 km\n",
    "\n",
    "val_x_max = 910000 - 500 # 900 km\n",
    "val_x_min = 850000 # - 200 km\n",
    "\n",
    "val_y_range = val_y_max - val_y_min\n",
    "val_x_range = val_x_max - val_x_min\n",
    "\n",
    "print(\"Y range in km\", val_y_range/1000)\n",
    "print(\"X range in km\", val_x_range/1000)\n",
    "\n",
    "# 138 training images\n",
    "(val_x_max - val_x_min + 500) * (val_y_max - val_y_min + 500) / 900000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (x: 120, y: 4200)\n",
      "Coordinates:\n",
      "  * x          (x) int32 850000 850500 851000 851500 ... 908500 909000 909500\n",
      "  * y          (y) int32 1799500 1799000 1798500 ... -299000 -299500 -300000\n",
      "Data variables:\n",
      "    mapping    |S1 b''\n",
      "    mask       (y, x) int8 1 1 1 1 1 1 1 1 1 1 1 1 2 ... 2 2 2 2 2 2 2 2 2 2 2 2\n",
      "    firn       (y, x) float32 0.0 0.0 0.0 0.0 0.0 ... 29.91 29.92 29.92 29.93\n",
      "    surface    (y, x) float32 1.298e+03 1.361e+03 ... 3.321e+03 3.321e+03\n",
      "    thickness  (y, x) float32 0.0 0.0 0.0 0.0 ... 2.61e+03 2.616e+03 2.622e+03\n",
      "    bed        (y, x) float32 1.298e+03 1.361e+03 1.304e+03 ... 705.2 699.1\n",
      "    errbed     (y, x) float32 10.0 10.0 10.0 10.0 ... 182.0 192.0 202.0 212.0\n",
      "    source     (y, x) int8 1 1 1 1 1 1 1 1 1 1 1 1 3 ... 5 5 5 5 5 5 5 5 5 5 5 5\n",
      "    dataid     (y, x) int8 1 1 1 1 1 1 1 1 1 1 1 1 0 ... 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "    geoid      (y, x) int16 17 17 17 17 17 17 17 ... -22 -22 -22 -22 -22 -22 -22\n",
      "Attributes: (12/17)\n",
      "    Conventions:                 CF-1.7\n",
      "    Title:                       BedMachine Antarctica\n",
      "    Author:                      Mathieu Morlighem\n",
      "    version:                     03-Jun-2022 (v3.4)\n",
      "    nx:                          13333.0\n",
      "    ny:                          13333.0\n",
      "    ...                          ...\n",
      "    ymax:                        3333000\n",
      "    spacing:                     500\n",
      "    no_data:                     -9999.0\n",
      "    license:                     No restrictions on access or use\n",
      "    Data_citation:               Morlighem M. et al., (2019), Deep glacial tr...\n",
      "    Notes:                       Data processed at the Department of Earth Sy...\n"
     ]
    }
   ],
   "source": [
    "def make_val_data(bm_xr, d_y_min, d_y_max, d_x_min, d_x_max):\n",
    "\n",
    "    train_bm_xr = bm_xr.sel(x = slice(d_x_min, d_x_max), \n",
    "                            y = slice(d_y_max, d_y_min))\n",
    "    # Print to check dims\n",
    "    print(train_bm_xr)\n",
    "\n",
    "    train_tensor = torch.tensor(train_bm_xr.bed.values).unsqueeze(0)\n",
    "\n",
    "    IMAGE_DIM = 60\n",
    "    N_ROW_IMAGES = int(train_bm_xr.bed.values.shape[0]/IMAGE_DIM)\n",
    "    N_COLUMN_IMAGES = int(train_bm_xr.bed.values.shape[1]/IMAGE_DIM)\n",
    "\n",
    "    image_tensor = torch.empty(size = (0, 1, IMAGE_DIM, IMAGE_DIM))\n",
    "\n",
    "    for row in range(0, N_ROW_IMAGES):\n",
    "        row_min = row * IMAGE_DIM\n",
    "        row_max = row_min + IMAGE_DIM\n",
    "\n",
    "        for column in range(0, N_COLUMN_IMAGES):\n",
    "            column_min = column * IMAGE_DIM\n",
    "            column_max = column_min + IMAGE_DIM\n",
    "\n",
    "            image_tensor = torch.cat((image_tensor, train_tensor[:, row_min : row_max, column_min : column_max].unsqueeze(0)), dim = 0)\n",
    "\n",
    "    min_values, _ = torch.min(image_tensor.reshape(image_tensor.shape[0], -1), dim = -1)\n",
    "    max_values, _ = torch.max(image_tensor.reshape(image_tensor.shape[0], -1), dim = -1)\n",
    "    range_values = max_values - min_values\n",
    "\n",
    "    norm = torch.subtract(input = image_tensor.reshape(image_tensor.shape[0], -1), other = min_values.unsqueeze(1))\n",
    "    norm = torch.div(input = norm, other = range_values.unsqueeze(1))\n",
    "    norm = norm.reshape(image_tensor.shape)\n",
    "    cont_755 = norm * (3*255)\n",
    "\n",
    "    # Low qual\n",
    "    pool = nn.AvgPool2d(4, stride = 4)\n",
    "    cont_755_lq = pool(cont_755)\n",
    "    \n",
    "    rgb = cont_755_to_rbb(cont_755)\n",
    "    rgb_lq = cont_755_to_rbb(cont_755_lq)\n",
    "\n",
    "    n_images = rgb.shape[0]\n",
    "\n",
    "    for i in range(n_images):\n",
    "        # Create filename: string with contant length\n",
    "        number = str(i)\n",
    "        while(len(number) < 4):\n",
    "            number = '0' + number\n",
    "\n",
    "        name_hr = \"datasets/ANT_val/ANT_val_HR_sub/\" + number + \".png\"\n",
    "        # name_lr = \"datasets/ANT_val/ANT_val_LR_sub/X4_sub/\" + number + \"x4\" + \".png\"\n",
    "        name_lr = \"datasets/ANT_val/ANT_val_LR_sub/X4_sub/\" + number + \".png\"\n",
    "\n",
    "        # following https://data.vision.ee.ethz.ch/cvl/DIV2K/\n",
    "        write_png(rgb[i, :, :, :].type(torch.uint8), filename = name_hr)\n",
    "        write_png(rgb_lq[i, :, :, :].type(torch.uint8), filename = name_lr)\n",
    "    \n",
    "make_val_data(bm_xr, val_y_min, val_y_max, val_x_min, val_x_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
